# Hello-algo笔记

[TOC]



# 复杂度分析（学完回头再看一遍，第一次有很多名词不熟悉）

## 迭代与递归

### 递归

#### 调用栈

递归函数每次调用自身时，系统都会为新开启的函数分配内存，以存储局部变量、调用地址和其他信息等。

**递归通常比迭代更加耗费内存空间**。

**递归通常比循环的时间效率更低**。

#### 尾递归

**如果函数在返回前的最后一步才进行递归调用**，则该函数可以被编译器或解释器优化，使其在空间效率上与迭代相当。这种情况被称为尾递归（tail recursion）。

#### 递归树

“斐波那契数列”为例

**这意味着从一个调用产生了两个调用分支**。这样不断递归调用下去，最终将产生一棵层数为 𝑛 的递归树（recursion tree）。

## 时间复杂度

### 渐近上界

𝑂(𝑛) ，这个数学符号称为大 𝑂 记号（big-𝑂 notation），表示函数 𝑇(𝑛) 的渐近上界（asymptotic upper bound）。

函数渐近上界

若存在正实数 𝑐 和实数 𝑛0 ，使得对于所有的 𝑛>𝑛0 ，均有 𝑇(𝑛)≤𝑐⋅𝑓(𝑛) ，则可认为 𝑓(𝑛) 给出了 𝑇(𝑛) 的一个渐近上界，记为 𝑇(𝑛)=𝑂(𝑓(𝑛)) 。

### 常见类型

常数阶<对数阶<线性阶<线性对数阶<平方阶<指数阶<阶乘

#### 平方阶

冒泡排序

#### 指数阶

指数阶增长非常迅速，在穷举法（暴力搜索、回溯等）中比较常见。对于数据规模较大的问题，指数阶是不可接受的，通常需要使用动态规划或贪心算法等来解决。

### 最差、最佳、平均时间复杂度

**算法的时间效率往往不是固定的，而是与输入数据的分布有关**。假设输入一个长度为 𝑛 的数组 `nums` ，其中 `nums` 由从 1 至 𝑛 的数字组成，每个数字只出现一次；但元素顺序是随机打乱的，任务目标是返回元素 1 的索引。我们可以得出以下结论。

- 当 `nums = [?, ?, ..., 1]` ，即当末尾元素是 1 时，需要完整遍历数组，**达到最差时间复杂度 𝑂(𝑛)** 。
- 当 `nums = [1, ?, ?, ...]` ，即当首个元素为 1 时，无论数组多长都不需要继续遍历，**达到最佳时间复杂度 Ω(1)** 。

“最差时间复杂度”对应函数渐近上界，使用大 𝑂 记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用 Ω 记号表示

## 空间复杂度

记不住，到时候回头再看

暂存空间可分为暂存数据、栈帧空间和指令空间，其中栈帧空间通常仅在递归函数中影响空间复杂度。

- 常见空间复杂度从低到高排列有 𝑂(1)、𝑂(log⁡𝑛)、𝑂(𝑛)、𝑂(𝑛2) 和 𝑂(2𝑛) 等。

# 数据结构

## 数据结构分类

**所有数据结构都是基于数组、链表或二者的组合实现的**

- **基于数组可实现**：栈、队列、哈希表、树、堆、图、矩阵、张量（维度 ≥3 的数组）等。
- **基于链表可实现**：栈、队列、哈希表、树、堆、图等。

## 基本数据类型

**基本数据类型是 CPU 可以直接进行运算的类型**，在算法中直接被使用，主要包括以下几种。

- 整数类型 `byte`、`short`、`int`、`long` 。
- 浮点数类型 `float`、`double` ，用于表示小数。
- 字符类型 `char` ，用于表示各种语言的字母、标点符号甚至表情符号等。
- 布尔类型 `bool` ，用于表示“是”与“否”判断。

**基本数据类型提供了数据的“内容类型”，而数据结构提供了数据的“组织方式”**

## 数字编码

- 整数在计算机中是以补码的形式存储的。在补码表示下，计算机可以对正数和负数的加法一视同仁，不需要为减法操作单独设计特殊的硬件电路，并且不存在正负零歧义的问题。
- 浮点数的编码由 1 位符号位、8 位指数位和 23 位分数位构成。由于存在指数位，因此浮点数的取值范围远大于整数，代价是牺牲了精度。



## 字符编码

后面复杂度有点没看懂，回头再看



- ASCII 码是最早出现的英文字符集，长度为 1 字节，共收录 127 个字符。GBK 字符集是常用的中文字符集，共收录两万多个汉字。Unicode 致力于提供一个完整的字符集标准，收录世界上各种语言的字符，从而解决由于字符编码方法不一致而导致的乱码问题。
- UTF-8 是最受欢迎的 Unicode 编码方法，通用性非常好。它是一种变长的编码方法，具有很好的扩展性，有效提升了存储空间的使用效率。

# 数组与链表

## 数组

- 数组存储在连续的内存空间内，且元素类型相同。这种做法包含丰富的先验信息，系统可以利用这些信息来优化数据结构的操作效率。

  - **空间效率高**：数组为数据分配了连续的内存块，无须额外的结构开销。
  - **支持随机访问**：数组允许在 𝑂(1) 时间内访问任何元素。
  - **缓存局部性**：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。

  连续空间存储是一把双刃剑，其存在以下局限性。

  - **插入与删除效率低**：当数组中元素较多时，插入与删除操作需要移动大量的元素。
  - **长度不可变**：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。
  - **空间浪费**：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。

## 链表

链表（linked list）是一种线性数据结构，其中的每个元素都是一个节点对象，各个节点通过“引用”相连接。

链表的组成单位是节点（node）对象。

**链表比数组占用更多的内存空间**。

**我们通常将头节点当作链表的代称**，

单向链表通常用于实现栈、队列、哈希表和图等数据结构。

双向链表常用于需要快速查找前一个和后一个元素的场景。

环形链表常用于需要周期性操作的场景，比如操作系统的资源调度。

## 列表

动态数组

- 链表天然可以看作一个列表，其支持元素增删查改操作，并且可以灵活动态扩容。
- 数组也支持元素增删查改，但由于其长度不可变，因此只能看作一个具有长度限制的列表。

**许多编程语言中的标准库提供的列表是基于动态数组实现的**

## 内存与缓存

**数组具有更高的缓存命中率，因此它在操作效率上通常优于链表**

- 在做算法题时，我们会倾向于**选择基于数组实现的栈**，因为它提供了更高的操作效率和随机访问的能力，代价仅是需要预先为数组分配一定的内存空间。
- 如果**数据量非常大、动态性很高、栈的预期大小难以估计**，那么基于链表实现的栈更加合适。链表能够将大量数据分散存储于内存的不同部分，并且避免了数组扩容产生的额外开销

# 栈与队列

## 栈

### 链表实现

头节点做栈顶

### 数组实现

数组尾部做栈顶

### 栈的典型应用

**浏览器中的后退与前进、软件中的撤销与反撤销**。

**程序内存管理**。

## 队列

```
from collections import deque

# 初始化队列
# 在 Python 中，我们一般将双向队列类 deque 当作队列使用
# 虽然 queue.Queue() 是纯正的队列类，但不太好用，因此不推荐
```

### 基于链表实现

将链表的“头节点”和“尾节点”分别视为“队首”和“队尾”，规定队尾仅可添加节点，队首仅可删除节点。

### 基于数组实现

使用一个变量 `front` 指向队首元素的索引，并维护一个变量 `size` 用于记录队列长度。定义 `rear = front + size` ，这个公式计算出的 `rear` 指向队尾元素之后的下一个位置。

#### 典型应用

**淘宝订单**。

**各类待办事项**。

### 双向队列

#### 双向队列应用

双向队列兼具栈与队列的逻辑，**因此它可以实现这两者的所有应用场景，同时提供更高的自由度**。

我们知道，软件的“撤销”功能通常使用栈来实现：系统将每次更改操作 `push` 到栈中，然后通过 `pop` 实现撤销。然而，考虑到系统资源的限制，软件通常会限制撤销的步数（例如仅允许保存 50 步）。当栈的长度超过 50 时，软件需要在栈底（队首）执行删除操作。**但栈无法实现该功能，此时就需要使用双向队列来替代栈**。请注意，“撤销”的核心逻辑仍然遵循栈的先入后出原则，只是双向队列能够更加灵活地实现一些额外逻辑。

### 小结

- 栈是一种遵循先入后出原则的数据结构，可通过数组或链表来实现。
- 在时间效率方面，栈的数组实现具有较高的平均效率，但在扩容过程中，单次入栈操作的时间复杂度会劣化至 𝑂(𝑛) 。相比之下，栈的链表实现具有更为稳定的效率表现。
- 在空间效率方面，栈的数组实现可能导致一定程度的空间浪费。但需要注意的是，链表节点所占用的内存空间比数组元素更大。
- 队列是一种遵循先入先出原则的数据结构，同样可以通过数组或链表来实现。在时间效率和空间效率的对比上，队列的结论与前述栈的结论相似。
- 双向队列是一种具有更高自由度的队列，它允许在两端进行元素的添加和删除操作。

# 哈希表

哈希表（hash table），又称散列表，它通过建立键 `key` 与值 `value` 之间的映射，实现高效的元素查询。

## 哈希函数

输入一个 `key` ，哈希函数的计算过程分为以下两步。

1. 通过某种哈希算法 `hash()` 计算得到哈希值。
2. 将哈希值对桶数量（数组长度）`capacity` 取模，从而获取该 `key` 对应的数组索引 `index` 。



## 扩容

负载因子（load factor）是哈希表的一个重要概念，其定义为哈希表的元素数量除以桶数量，用于衡量哈希冲突的严重程度，**也常作为哈希表扩容的触发条件**。例如在 Java 中，当负载因子超过 0.75 时，系统会将哈希表扩容至原先的 2 倍。

## 哈希冲突

多个输入对应同一输出的情况称为哈希冲突（hash collision）。

哈希表的结构改良方法主要包括“链式地址”和“开放寻址”。

1. 改良哈希表数据结构，**使得哈希表可以在出现哈希冲突时正常工作**。
2. 仅在必要时，即当哈希冲突比较严重时，才执行扩容操作。

### 链式地址(记得回头看)

链式地址（separate chaining）将单个元素转换为链表，将键值对作为链表节点，将所有发生冲突的键值对都存储在同一链表中。



当链表很长时，查询效率 𝑂(𝑛) 很差。**此时可以将链表转换为“AVL 树”或“红黑树”**，从而将查询操作的时间复杂度优化至 𝑂(log⁡𝑛) 。

### 开放寻址

开放寻址（open addressing）不引入额外的数据结构，而是通过“多次探测”来处理哈希冲突，探测方式主要包括线性探测、平方探测和多次哈希等。

#### 线性探测

线性探测采用固定步长的线性搜索来进行探测，其操作方法与普通哈希表有所不同。

- **插入元素**：通过哈希函数计算桶索引，若发现桶内已有元素，则从冲突位置向后线性遍历（步长通常为 1 ），直至找到空桶，将元素插入其中。
- **查找元素**：若发现哈希冲突，则使用相同步长向后进行线性遍历，直到找到对应元素，返回 `value` 即可；如果遇到空桶，说明目标元素不在哈希表中，返回 `None` 。

删除：

**不能在开放寻址哈希表中直接删除元素**

利用懒删除（lazy deletion）机制，**用一个常量 `TOMBSTONE` 来标记这个桶**

**懒删除可能会加速哈希表的性能退化**。这是因为每次删除操作都会产生一个删除标记，随着 `TOMBSTONE` 的增加，搜索时间也会增加，因为线性探测可能需要跳过多个 `TOMBSTONE` 才能找到目标元素。

#### 平方探测

缓解线性探测的聚集效应。有助于数据分布得更加均匀

平方探测可能不会探测整个哈希表，这意味着即使哈希表中有空桶，平方探测也可能无法访问到它。

#### 多次哈希

多次哈希方法使用多个哈希函数 𝑓1(𝑥)、𝑓2(𝑥)、𝑓3(𝑥)、… 进行探测。

多次哈希方法不易产生聚集，但多个哈希函数会带来额外的计算量。

### 编程语言的选择[¶](https://www.hello-algo.com/chapter_hashing/hash_collision/#623)

各种编程语言采取了不同的哈希表实现策略，下面举几个例子。

- Python 采用开放寻址。字典 `dict` 使用伪随机数进行探测。
- Java 采用链式地址。
- Go 采用链式地址。

## 哈希算法

无论是开放寻址还是链式地址，**它们只能保证哈希表可以在发生冲突时正常工作，而无法减少哈希冲突的发生**

目标：确定性、效率高、均匀分布

设计：

加法哈希、乘法哈希、异或(^)哈希、旋转哈希